---
title: "p8105_hw5_jl5934"
author: "Jesus Luevano"
date: "2023-11-03"
output: html_document
---

```{r}
library(tidyverse)
```

# Problem 1 - WaPo

```{r WaPo dataset read}
WaPo.df <- read_csv("data/homicide-data.csv") %>%
  janitor::clean_names()
```

The data includes `r print(colnames(WaPo.df))`, with a total of `r nrow(WaPo.df)` observations. 

```{r WaPo tidy}
unsolved <- WaPo.df %>%
  filter(disposition %in% c("Closed without arrest", "Open/No arrest")) %>%
  mutate(city_state = 
           paste0(city,", ",state)) %>%
  group_by(city_state) %>%
  summarize(unsolved = n()) 

total_homicides <- WaPo.df %>%
  mutate(city_state = 
           paste0(city,", ",state)) %>%
  group_by(city_state) %>%
  summarize(total = n()) 

solved <- WaPo.df %>%
  filter(disposition %in% c("Closed by arrest")) %>%
  mutate(city_state = 
           paste0(city,", ",state)) %>%
  group_by(city_state) %>%
  summarize(solved = n())

```

```{r WaPO filter,eval=FALSE }
prop_homicide <- full_join(unsolved, solved, by = "city_state") %>%
  replace(is.na(.), 0) %>%
  filter(city_state == "Baltimore, MD") %>%
  column_to_rownames(var = "city_state") %>%
    as.matrix() 

test <- broom::tidy(prop.test(prop_homicide))

tibble(
  prop_unsolved = test[["estimate"]],
  CI_low = test[["conf.low"]],
  CI_upper = test[["conf.high"]]
)

```

```{r}
cities = as.vector(total_homicides[["city_state"]])

prop_hom = function(x) {
  
  prop_homicide <- full_join(unsolved, solved, by = "city_state") %>%
  replace(is.na(.), 0) %>%
  filter(city_state == x) %>%
  column_to_rownames(var = "city_state") %>%
    as.matrix() 

test <- broom::tidy(prop.test(prop_homicide))

tibble(
  city = x,
  prop_unsolved = test[["estimate"]],
  CI_low = test[["conf.low"]],
  CI_upper = test[["conf.high"]]
)
  
}

WaPo_output = map(cities, prop_hom) %>%
  bind_rows()
```

```{r}
ggplot(WaPo_output, aes(x = fct_reorder(city, prop_unsolved), y = prop_unsolved)) +
  geom_point(stat = "identity") +
  geom_errorbar(aes(ymin = CI_low, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 45, size = 5, hjust = 1))
```


# Problem 2

```{r prep trial data}
file_list <- list.files("data/data/")

file_reader = function(x) {
  
  data_x = read_csv(paste0("data/data/", x))
  name_x = gsub(".csv","",x)
  
  tibble(
    name = name_x,
    data = as.data.frame(data_x)
  ) %>% 
  unnest(cols = data)
    
}

output = map(file_list, file_reader) %>%
  bind_rows() %>%
  pivot_longer(
    cols = week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "value"
  ) %>%
  rename("subject" = "name") %>%
  mutate(group = 
           ifelse(subject %in% c("con_01","con_02","con_03","con_04","con_05","con_06","con_07","con_08","con_09","con_10"), "control", "experimental"))

```

```{r plot trial data}
ggplot(data = output, aes(x = week, y = value, group = subject)) +
  geom_point(aes(color = subject)) +
  geom_line(aes(color = subject)) +
  facet_grid(~group)

```

* Looking at the plot, we can see that in general the control group had lower values than the experimental, with some actually going negative, but the experimental group had much more change over time. 

* Specifically, they started at similar values centered around 2.5, but their mean at the end of the 8-week study was closer to 1.25, whereas the experimental group increased by the end of the study to general mean closer to 5 among all the subjects. This shows within subjects in a group there is significant association as to where their final outcome value will be based on their starting. 



# Problem 3

```{r}
sim_mean_test = function(n = 30, mu, sigma = 5) {
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma),
    )
  
  t_test = broom::tidy(t.test(x ~ 1, data = sim_data))
} 

#means = 0:6
#iterations = 1:5000

output_sim =
  tibble(mu = 0:6) %>%
  mutate(
    output_sim_means = map(.x = mu, ~replicate(50, sim_mean_test(mu = .x)))
    )

output_sim = output_sim %>%
  mutate(output_dfs = bind_rows(output_sim_means))
    
    output_dfs = map(output_sim_means, bind_rows)
  ) %>%
  select(-output_sim_means)
```

```{r}
output_sum = output_sum %>%
  unnest(output_dfs) %>%
  select
```


```{r create sim_0}
#mu_list = 0:6
output_sim = vector("list", 5000)
file_list = 1:50

sim_mean_test = function(n = 30, mu = 0, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma)
  )
  
  t_test = broom::tidy(t.test(sim_data$x, mu = 0, x ~ 1))
  
  power_data = tibble(
    estimate = t_test[["estimate"]],
    p_value = t_test[["p.value"]],
    mean = mu
    )
}

output_sim_0 = map(file_list, sim_mean_test) %>%
  bind_rows()

```


```{r create sim1:6}
output_sim = vector("list", 5000)
file_list = 1:5000

sim_mean_test = function(n = 30, mu = 1, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma), 
    mu = mu
  )
  
  t_test = broom::tidy(t.test(x ~ 1, data = sim_data, mu = 0))
  
  power_data = tibble(
    estimate = t_test[["estimate"]],
    p_value = t_test[["p.value"]],
    mean = mu
    )
}

output_sim_1 = map(file_list, sim_mean_test) %>%
  bind_rows() #%>%   mutate(mu = mu_list)

output_sim = vector("list", 5000)
file_list = 1:5000


sim_mean_test = function(n = 30, mu = 2, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma), 
    mu = mu
  )
  
  t_test = broom::tidy(t.test(x ~ 1, data = sim_data, mu = 0))
  
  power_data = tibble(
    estimate = t_test[["estimate"]],
    p_value = t_test[["p.value"]],
    mean = mu
    )
}

output_sim_2 = map(file_list, sim_mean_test) %>%
  bind_rows() #%>%   mutate(mu = mu_list)

output_sim = vector("list", 5000)
file_list = 1:5000


sim_mean_test = function(n = 30, mu = 3, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma), 
    mu = mu
  )
  
  t_test = broom::tidy(t.test(x ~ 1, data = sim_data, mu = 0))
  
  power_data = tibble(
    estimate = t_test[["estimate"]],
    p_value = t_test[["p.value"]],
    mean = mu
    )
}

output_sim_3 = map(file_list, sim_mean_test) %>%
  bind_rows() #%>%   mutate(mu = mu_list)

output_sim = vector("list", 5000)
file_list = 1:5000


sim_mean_test = function(n = 30, mu = 4, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma), 
    mu = mu
  )
  
  t_test = broom::tidy(t.test(x ~ 1, data = sim_data, mu = 0))
  
  power_data = tibble(
    estimate = t_test[["estimate"]],
    p_value = t_test[["p.value"]],
    mean = mu
    )
}

output_sim_4 = map(file_list, sim_mean_test) %>%
  bind_rows() #%>%   mutate(mu = mu_list)

output_sim = vector("list", 5000)
file_list = 1:5000


sim_mean_test = function(n = 30, mu = 5, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma), 
    mu = mu
  )
  
  t_test = broom::tidy(t.test(x ~ 1, data = sim_data, mu = 0))
  
  power_data = tibble(
    estimate = t_test[["estimate"]],
    p_value = t_test[["p.value"]],
    mean = mu
    )
}

output_sim_5 = map(file_list, sim_mean_test) %>%
  bind_rows() #%>%   mutate(mu = mu_list)

output_sim = vector("list", 5000)
file_list = 1:5000


sim_mean_test = function(n = 30, mu = 6, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma), 
    mu = mu
  )
  
  t_test = broom::tidy(t.test(x ~ 1, data = sim_data, mu = 0))
  
  power_data = tibble(
    estimate = t_test[["estimate"]],
    p_value = t_test[["p.value"]],
    mean = mu
    )
}

output_sim_6 = map(file_list, sim_mean_test) %>%
  bind_rows() #%>%   mutate(mu = mu_list)
```

```{r merge all}
output_sum_all <- bind_rows(output_sim_0, output_sim_1, output_sim_2, output_sim_3, output_sim_4, output_sim_5, output_sim_6) %>%
  mutate(significant = ifelse(p_value < 0.05, "reject_null", "not_reject_null"))

```

```{r plot power}
ggplot(output_sum_all, aes(x = mean, fill = factor(significant))) +
  geom_bar(position = "fill") +
  labs(title = "Proportion of rejection by change in sample mean, Power analysis by effect Size", fill = "Null Rejection") + 
  xlab("True mean(Mu)") + ylab("Proportion")
       
```

* Looking at the power among different population means, the proportion where null rejected is about 0.05 was when sample mean was 0 and population mean was 0. 

* However, as effect size (mean increases from 0 to 1:6) the power should increase, i.e. we should note that the number of rejections increases as it is easier to distinguish a difference from 0 to 1:6 with stable SD = 5. This is what we see as there is an exponential increase of power when the mean goes to 1, and after stays > 95%. 

```{r plot mean sample vs population}
output_sum_all %>%
  group_by(mean, significant) %>%
  summarize(mu_hat = mean(estimate)) %>%
  ggplot(aes(x = mean, y = mu_hat)) + 
  geom_point() +
  facet_grid(significant ~ mean) +
  labs(title = "Mean set compared to mu_hat average of all tests")

output_sum_all %>%
  filter(significant == "reject_null") %>%
  group_by(mean) %>%
  summarize(mu_hat = mean(estimate)) %>%
  ggplot(aes(x = mean, y = mu_hat)) + 
  geom_point() +
  labs(title = "Mean set compared to mu_hat average of tests where null hypothesis was rejected")


```

* We do see that the average value of mu-hat for tests where the null hypothesis was rejected (i.e. p-value <0.05) is essentially equal to the true value of mu that we set. This makes sense as we are rejecting that the mu we set was equal to the null-mu fro the t-test (zero), so it should be close to the mu we tested it on, the one we set 0:6
